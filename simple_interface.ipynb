{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning, cannot find cuda-compiled version of RoPE2D, using a slow pytorch version instead\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import math\n",
    "import builtins\n",
    "import datetime\n",
    "import gradio\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import functools\n",
    "import trimesh\n",
    "import copy\n",
    "from scipy.spatial.transform import Rotation\n",
    "\n",
    "from dust3r.inference import inference\n",
    "from dust3r.image_pairs import make_pairs\n",
    "from dust3r.utils.image import load_images, rgb\n",
    "from dust3r.utils.device import to_numpy\n",
    "from dust3r.viz import add_scene_cam, CAM_COLORS, OPENGL, pts3d_to_trimesh, cat_meshes\n",
    "from dust3r.cloud_opt import global_aligner, GlobalAlignerMode\n",
    "\n",
    "import matplotlib.pyplot as pl\n",
    "\n",
    "from dust3r.demo import get_reconstructed_scene, get_3D_model_from_scene\n",
    "from dust3r.model import AsymmetricCroCo3DStereo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... loading model from ./docker/files/checkpoints/DUSt3R_ViTLarge_BaseDecoder_512_dpt.pth\n",
      "instantiating : AsymmetricCroCo3DStereo(enc_depth=24, dec_depth=12, enc_embed_dim=1024, dec_embed_dim=768, enc_num_heads=16, dec_num_heads=12, pos_embed='RoPE100', patch_embed_cls='PatchEmbedDust3R', img_size=(512, 512), head_type='dpt', output_mode='pts3d', depth_mode=('exp', -inf, inf), conf_mode=('exp', 1, inf), landscape_only=False)\n",
      "<All keys matched successfully>\n"
     ]
    }
   ],
   "source": [
    "outdir = \"output\"\n",
    "device = \"cuda\"\n",
    "silent = False\n",
    "image_size = 512\n",
    "filelist = \"./images_in\"\n",
    "schedule = \"linear\" # or \"cosine\"\n",
    "niter = 300 # number of iters\n",
    "min_conf_thr = 3\n",
    "as_pointcloud = True\n",
    "mask_sky = False\n",
    "clean_depth = True\n",
    "transparent_cams = False\n",
    "cam_size = 0.05\n",
    "scenegraph_type = \"complete\"\n",
    "winsize = 1\n",
    "refid = 0\n",
    "\n",
    "model = AsymmetricCroCo3DStereo.from_pretrained(\"./docker/files/checkpoints/DUSt3R_ViTLarge_BaseDecoder_512_dpt.pth\").to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Loading images from ./images_in\n",
      " - adding 0.png with resolution 640x512 --> 512x400\n",
      " - adding 1.png with resolution 640x512 --> 512x400\n",
      " - adding 2.png with resolution 640x512 --> 512x400\n",
      " - adding 3.png with resolution 640x512 --> 512x400\n",
      " - adding 4.png with resolution 640x512 --> 512x400\n",
      " - adding 5.png with resolution 640x512 --> 512x400\n",
      " - adding 6.png with resolution 640x512 --> 512x400\n",
      " - adding 7.png with resolution 640x512 --> 512x400\n",
      " - adding 8.png with resolution 640x512 --> 512x400\n",
      " - adding 9.png with resolution 640x512 --> 512x400\n",
      " (Found 10 images)\n",
      ">> Inference with model on 90 image pairs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 90/90 [01:08<00:00,  1.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " init edge (1*,0*) score=77.61289978027344\n",
      " init edge (1,7*) score=46.66046905517578\n",
      " init edge (1,3*) score=45.55316162109375\n",
      " init edge (2*,3) score=40.528236389160156\n",
      " init edge (2,6*) score=66.45589447021484\n",
      " init edge (2,9*) score=57.878299713134766\n",
      " init edge (8*,6) score=51.02920150756836\n",
      " init edge (2,5*) score=43.53687286376953\n",
      " init edge (2,4*) score=42.88144302368164\n",
      " init loss = 0.014015794731676579\n",
      "Global alignement - optimizing for:\n",
      "['pw_poses', 'im_depthmaps', 'im_poses', 'im_focals']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████| 300/300 [01:40<00:00,  3.00it/s, lr=3.433e-05 loss=0.0077132]\n"
     ]
    }
   ],
   "source": [
    "scene, pts3d, rgbimg, cams2world, confs = get_reconstructed_scene(outdir, model, device, silent, image_size, filelist, schedule, niter, min_conf_thr,\n",
    "                            as_pointcloud, mask_sky, clean_depth, transparent_cams, cam_size,\n",
    "                            scenegraph_type, winsize, refid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = to_numpy(scene.get_masks())\n",
    "\n",
    "pts3d = to_numpy(pts3d)\n",
    "\n",
    "\n",
    "pts = np.concatenate([p[m] for p, m in zip(pts3d, mask)])\n",
    "col = np.concatenate([p[m] for p, m in zip(rgbimg, mask)])\n",
    "conf = np.concatenate([p[m] for p, m in zip(confs, mask)])\n",
    "\n",
    "np.savetxt(\"./output/out.csv\",np.hstack((pts, col, conf)), delimiter=\",\")\n",
    "\n",
    "for i in range(0,len(cams2world)):\n",
    "    np.savetxt(\"./output/\"+str(i)+\".csv\", to_numpy(cams2world[i]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.7855781 ,  0.35925955, -0.5037852 ,  0.14591828],\n",
       "       [-0.37338138,  0.92447436,  0.0770289 , -0.02858463],\n",
       "       [ 0.4934099 ,  0.1275918 ,  0.8603876 ,  0.0330322 ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  1.        ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_numpy(cams2world[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
